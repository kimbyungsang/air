{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, csv\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore(target_file, separator=',', fieldnames=None, binary_features=list(), numeric_features=list(), max_rows=20000):\n",
    "    \"\"\"\n",
    "    Create MinMaxScaler and DictVectorizer from online stream\n",
    "    \n",
    "    Parameters:\n",
    "    target file: stream file\n",
    "    separator: delimiter\n",
    "    fieldnames: field label (optional)\n",
    "    binary_features: list of qualitative features\n",
    "    numeric_features: list of numeric features\n",
    "    max_rows: a number of row from stream file (None is possible)\n",
    "    \"\"\"\n",
    "    features = dict()\n",
    "    min_max = dict()\n",
    "    vectorizer = DictVectorizer(sparse=False)\n",
    "    scaler = MinMaxScaler()\n",
    "    with open(target_file, 'r') as R:\n",
    "        iterator = csv.DictReader(R, fieldnames, delimiter=separator)\n",
    "        for n, row in enumerate(iterator):\n",
    "            #data exploration\n",
    "            for k,v in row.items():\n",
    "                if k in binary_features:\n",
    "                    if k+'_'+v not in features:\n",
    "                        features[k+'_'+v] = 0\n",
    "                elif k in numeric_features:\n",
    "                    v = float(v)\n",
    "                    if k not in features:\n",
    "                        features[k] = 0\n",
    "                        min_max[k] = [v,v]\n",
    "                    else:\n",
    "                        if v < min_max[k][0]:\n",
    "                            min_max[k][0] = v\n",
    "                        elif v > min_max[k][1]:\n",
    "                            min_max[k][1] = v\n",
    "                else:\n",
    "                    pass\n",
    "            if max_rows and n > max_rows:\n",
    "                break\n",
    "\n",
    "    vectorizer.fit([features])\n",
    "    A = vectorizer.transform([{f:0 if f not in min_max else min_max[f][0] for f in vectorizer.feature_names_},\\\n",
    "                            {f:1 if f not in min_max else min_max[f][1] for f in vectorizer.feature_names_}])\n",
    "    scaler.fit(A)\n",
    "    return vectorizer, scaler\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_examples(target_file, vectorizer, binary_features, numeric_features, target, min_max=None, separator=',', \\\n",
    "                 fieldnames=None, sparse=True):\n",
    "    \"\"\"\n",
    "    return generator from online stream\n",
    "    \"\"\"\n",
    "    with open(target_file, 'r') as R:\n",
    "        iterator = csv.DictReader(R, fieldnames, delimiter=separator)\n",
    "        for n, row in enumerate(iterator):\n",
    "            \n",
    "            #data processing\n",
    "            stream_row = {}\n",
    "            response = np.array([float(row[target])])\n",
    "            for k,v in row.items():\n",
    "                if k in binary_features:\n",
    "                    stream_row[k+'_'+v]=1.0\n",
    "                else:\n",
    "                    if k in numeric_features:\n",
    "                        stream_row[k] = float(v)\n",
    "            if min_max:\n",
    "                features = min_max.transform(vectorizer.transform([stream_row]))\n",
    "            else:\n",
    "                features = vectorizer.transform([stream_row])\n",
    "            if sparse:\n",
    "                yield(csr_matrix(features),response,n)\n",
    "            else:\n",
    "                yield(features, response, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: \n",
      "atemp:[0.00,1.00] \n",
      "holiday_0:[0.00,1.00] \n",
      "holiday_1:[0.00,1.00] \n",
      "hr_0:[0.00,1.00] \n",
      "hr_1:[0.00,1.00] \n",
      "hr_10:[0.00,1.00] \n",
      "hr_11:[0.00,1.00] \n",
      "hr_12:[0.00,1.00] \n",
      "hr_13:[0.00,1.00] \n",
      "hr_14:[0.00,1.00] \n",
      "hr_15:[0.00,1.00] \n",
      "hr_16:[0.00,1.00] \n",
      "hr_17:[0.00,1.00] \n",
      "hr_18:[0.00,1.00] \n",
      "hr_19:[0.00,1.00] \n",
      "hr_2:[0.00,1.00] \n",
      "hr_20:[0.00,1.00] \n",
      "hr_21:[0.00,1.00] \n",
      "hr_22:[0.00,1.00] \n",
      "hr_23:[0.00,1.00] \n",
      "hr_3:[0.00,1.00] \n",
      "hr_4:[0.00,1.00] \n",
      "hr_5:[0.00,1.00] \n",
      "hr_6:[0.00,1.00] \n",
      "hr_7:[0.00,1.00] \n",
      "hr_8:[0.00,1.00] \n",
      "hr_9:[0.00,1.00] \n",
      "hum:[0.00,1.00] \n",
      "mnth_1:[0.00,1.00] \n",
      "mnth_10:[0.00,1.00] \n",
      "mnth_11:[0.00,1.00] \n",
      "mnth_12:[0.00,1.00] \n",
      "mnth_2:[0.00,1.00] \n",
      "mnth_3:[0.00,1.00] \n",
      "mnth_4:[0.00,1.00] \n",
      "mnth_5:[0.00,1.00] \n",
      "mnth_6:[0.00,1.00] \n",
      "mnth_7:[0.00,1.00] \n",
      "mnth_8:[0.00,1.00] \n",
      "mnth_9:[0.00,1.00] \n",
      "season_1:[0.00,1.00] \n",
      "season_2:[0.00,1.00] \n",
      "season_3:[0.00,1.00] \n",
      "season_4:[0.00,1.00] \n",
      "temp:[0.02,1.00] \n",
      "weathersit_1:[0.00,1.00] \n",
      "weathersit_2:[0.00,1.00] \n",
      "weathersit_3:[0.00,1.00] \n",
      "weathersit_4:[0.00,1.00] \n",
      "weekday_0:[0.00,1.00] \n",
      "weekday_1:[0.00,1.00] \n",
      "weekday_2:[0.00,1.00] \n",
      "weekday_3:[0.00,1.00] \n",
      "weekday_4:[0.00,1.00] \n",
      "weekday_5:[0.00,1.00] \n",
      "weekday_6:[0.00,1.00] \n",
      "windspeed:[0.00,0.85] \n",
      "workingday_0:[0.00,1.00] \n",
      "workingday_1:[0.00,1.00] \n",
      "yr_0:[0.00,1.00] \n",
      "yr_1:[0.00,1.00] \n"
     ]
    }
   ],
   "source": [
    "source = '/datasets/bikesharing/hour.csv'\n",
    "local_path = os.getcwd()\n",
    "b_vars = ['holiday', 'hr', 'mnth', 'season', 'weathersit', 'weekday', 'workingday', 'yr']\n",
    "n_vars = ['hum', 'temp', 'atemp', 'windspeed']\n",
    "std_row, min_max = explore(target_file=local_path+'/'+source, binary_features=b_vars, numeric_features=n_vars)\n",
    "print('Feature: ')\n",
    "for f,mv,mx in zip(std_row.feature_names_, min_max.data_min_, min_max.data_max_):\n",
    "    print('%s:[%0.2f,%0.2f] ' %(f,mv,mx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1624914:57:04 holdout RMSE: 276.604holdout RMSLE: 1.796\n",
      "1649914:57:04 holdout RMSE: 250.419holdout RMSLE: 1.706\n",
      "1674914:57:04 holdout RMSE: 250.639holdout RMSLE: 1.694\n",
      "1699914:57:04 holdout RMSE: 249.561holdout RMSLE: 1.702\n",
      "1724914:57:05 holdout RMSE: 234.840holdout RMSLE: 1.640\n",
      "X FINAL holdout RMSE: 224.404\n",
      "X FINAL holdout RMSLE: 1.594\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "SGD = SGDRegressor(loss='epsilon_insensitive', epsilon=0.001, penalty=None, random_state=1, average=True)\n",
    "val_rmse = 0\n",
    "val_rmsle = 0\n",
    "predictions_start = 16000\n",
    "\n",
    "def apply_log(x): return np.log(x + 1.0)\n",
    "def apply_exp(x): return np.exp(x) - 1.0\n",
    "\n",
    "for x,y,n in pull_examples(target_file=local_path+'/'+source, vectorizer=std_row, \\\n",
    "                          min_max=min_max, binary_features=b_vars, numeric_features=n_vars, target='cnt'):\n",
    "    y_log = apply_log(y)\n",
    "    #machine learning\n",
    "    if (n+1) >= predictions_start:\n",
    "        #holdout after N phase\n",
    "        predicted = SGD.predict(x)\n",
    "        val_rmse += (apply_exp(predicted)-y)**2\n",
    "        val_rmsle += (predicted - y_log)**2\n",
    "        if(n-predictions_start+1)% 250 == 0 and (n+1) > predictions_start:\n",
    "            print(n, end='')\n",
    "            print('%s holdout RMSE: %0.3f' % (time.strftime('%X'), (val_rmse/float(n-predictions_start+1))**0.5), end='')\n",
    "            print('holdout RMSLE: %0.3f'%((val_rmsle/float(n-predictions_start+1))**0.5))\n",
    "    else:\n",
    "        #learning phase\n",
    "        SGD.partial_fit(x,y_log)\n",
    "print('%s FINAL holdout RMSE: %0.3f' % (time.strftime('X'), (val_rmse/float(n-predictions_start+1))**0.5))\n",
    "print('%s FINAL holdout RMSLE: %0.3f' % (time.strftime('X'), (val_rmsle/float(n-predictions_start+1))**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: \n",
      "var_00:[1860.00,3845.00]\n",
      "var_01:[0.00,360.00]\n",
      "var_02:[0.00,54.00]\n",
      "var_03:[0.00,1348.00]\n",
      "var_04:[-166.00,589.00]\n",
      "var_05:[0.00,7097.00]\n",
      "var_06:[0.00,254.00]\n",
      "var_07:[87.00,254.00]\n",
      "var_08:[0.00,253.00]\n",
      "var_09:[0.00,7110.00]\n",
      "var_10:[0.00,1.00]\n",
      "var_11:[0.00,1.00]\n",
      "var_12:[0.00,1.00]\n",
      "var_13:[0.00,1.00]\n",
      "var_14:[0.00,1.00]\n",
      "var_15:[0.00,1.00]\n",
      "var_16:[0.00,1.00]\n",
      "var_17:[0.00,1.00]\n",
      "var_18:[0.00,1.00]\n",
      "var_19:[0.00,1.00]\n",
      "var_20:[0.00,1.00]\n",
      "var_21:[0.00,1.00]\n",
      "var_22:[0.00,1.00]\n",
      "var_23:[0.00,1.00]\n",
      "var_24:[0.00,1.00]\n",
      "var_25:[0.00,1.00]\n",
      "var_26:[0.00,1.00]\n",
      "var_27:[0.00,1.00]\n",
      "var_28:[0.00,0.00]\n",
      "var_29:[0.00,1.00]\n",
      "var_30:[0.00,1.00]\n",
      "var_31:[0.00,1.00]\n",
      "var_32:[0.00,1.00]\n",
      "var_33:[0.00,1.00]\n",
      "var_34:[0.00,1.00]\n",
      "var_35:[0.00,1.00]\n",
      "var_36:[0.00,1.00]\n",
      "var_37:[0.00,1.00]\n",
      "var_38:[0.00,1.00]\n",
      "var_39:[0.00,1.00]\n",
      "var_40:[0.00,1.00]\n",
      "var_41:[0.00,1.00]\n",
      "var_42:[0.00,1.00]\n",
      "var_43:[0.00,1.00]\n",
      "var_44:[0.00,1.00]\n",
      "var_45:[0.00,1.00]\n",
      "var_46:[0.00,1.00]\n",
      "var_47:[0.00,1.00]\n",
      "var_48:[0.00,1.00]\n",
      "var_49:[0.00,1.00]\n",
      "var_50:[0.00,1.00]\n",
      "var_51:[0.00,1.00]\n",
      "var_52:[0.00,1.00]\n",
      "var_53:[0.00,1.00]\n"
     ]
    }
   ],
   "source": [
    "source = 'datasets/shuffled_covtype.data'\n",
    "local_path = os.getcwd()\n",
    "n_vars = ['var_'+'0'*int(j<10)+str(j) for j in range(54)]\n",
    "std_row, min_max = explore(target_file=local_path+'/'+source, binary_features=list(), \\\n",
    "                           fieldnames=n_vars+['covertype'], numeric_features=n_vars, \\\n",
    "                          max_rows=50000)\n",
    "print('Feature: ')\n",
    "for f,mv,mx in zip(std_row.feature_names_, min_max.data_min_, min_max.data_max_):\n",
    "    print('%s:[%0.2f,%0.2f]' % (f,mv,mx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:20:12 Progressive accuracy at example 5000: 0.656\n",
      "15:20:32 Progressive accuracy at example 10000: 0.675\n",
      "15:20:51 Progressive accuracy at example 15000: 0.685\n",
      "15:21:10 Progressive accuracy at example 20000: 0.691\n",
      "15:21:28 Progressive accuracy at example 25000: 0.697\n",
      "15:21:47 Progressive accuracy at example 30000: 0.698\n",
      "15:22:06 Progressive accuracy at example 35000: 0.699\n",
      "15:22:24 Progressive accuracy at example 40000: 0.701\n",
      "15:22:44 Progressive accuracy at example 45000: 0.702\n",
      "15:23:03 Progressive accuracy at example 50000: 0.703\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "SGD = SGDClassifier(loss='hinge', penalty=None, random_state=1, average=True)\n",
    "accuracy = 0\n",
    "accuracy_record = list()\n",
    "predictions_start = 50\n",
    "sample = 5000\n",
    "early_stop = 50000\n",
    "\n",
    "for x,y,n in pull_examples(target_file=local_path+'/'+source, vectorizer=std_row, min_max=min_max, \\\n",
    "                          binary_features = list(), numeric_features=n_vars, \n",
    "                           fieldnames=n_vars+['covertype'], target='covertype'):\n",
    "    #learning phase\n",
    "    if n>predictions_start:\n",
    "        accuracy += int(int(SGD.predict(x))==y[0])\n",
    "        if n % sample == 0:\n",
    "            accuracy_record.append(accuracy/float(sample))\n",
    "            print('%s Progressive accuracy at example %i: %0.3f' % (time.strftime('%X'), n, np.mean(accuracy_record[-sample:])))\n",
    "            accuracy = 0\n",
    "    if early_stop and n >= early_stop:\n",
    "        break\n",
    "    SGD.partial_fit(x,y,classes=range(1,8))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TerminalIPythonApp] WARNING | Subcommand `ipython nbconvert` is deprecated and will be removed in future versions.\n",
      "[TerminalIPythonApp] WARNING | You likely want to use `jupyter nbconvert` in the future\n",
      "[NbConvertApp] Converting notebook SGD2SVM.ipynb to python\n",
      "[NbConvertApp] Writing 6356 bytes to SGD2SVM.py\n"
     ]
    }
   ],
   "source": [
    "!ipython nbconvert --to=python SGD2SVM.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
